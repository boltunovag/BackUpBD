# Домашнее задание к занятию "`Резервное копирование данных`" - `Болтунов Алексей`


### Инструкция по выполнению домашнего задания

   1. Сделайте `fork` данного репозитория к себе в Github и переименуйте его по названию или номеру занятия, например, https://github.com/имя-вашего-репозитория/git-hw или  https://github.com/имя-вашего-репозитория/7-1-ansible-hw).
   2. Выполните клонирование данного репозитория к себе на ПК с помощью команды `git clone`.
   3. Выполните домашнее задание и заполните у себя локально этот файл README.md:
      - впишите вверху название занятия и вашу фамилию и имя
      - в каждом задании добавьте решение в требуемом виде (текст/код/скриншоты/ссылка)
      - для корректного добавления скриншотов воспользуйтесь [инструкцией "Как вставить скриншот в шаблон с решением](https://github.com/netology-code/sys-pattern-homework/blob/main/screen-instruction.md)
      - при оформлении используйте возможности языка разметки md (коротко об этом можно посмотреть в [инструкции  по MarkDown](https://github.com/netology-code/sys-pattern-homework/blob/main/md-instruction.md))
   4. После завершения работы над домашним заданием сделайте коммит (`git commit -m "comment"`) и отправьте его на Github (`git push origin`);
   5. Для проверки домашнего задания преподавателем в личном кабинете прикрепите и отправьте ссылку на решение в виде md-файла в вашем Github.
   6. Любые вопросы по выполнению заданий спрашивайте в чате учебной группы и/или в разделе “Вопросы по заданию” в личном кабинете.
   
Желаем успехов в выполнении домашнего задания!
   
### Дополнительные материалы, которые могут быть полезны для выполнения задания

1. [Руководство по оформлению Markdown файлов](https://gist.github.com/Jekins/2bf2d0638163f1294637#Code)

---

### Задание 1

Для обеспечения надёжности необходимо комбинировать несколько стратегий резервного копирования и высокой доступности. Для задачи восстановления на конец предыдущего дня достаточно классической схемы с ежедневным полным резервным копированием. Это просто и надёжно, но не защищает от потери данных за текущий рабочий день.

Чтобы минимизировать потери и восстановить состояние на момент, максимально близкий к сбою (например, за час до него), требуется более сложный подход. Стандартной практикой здесь является использование полных резервных копий в сочетании с резервным копированием журнала транзакций. Полные бэкапы создаются реже (например, раз в сутки), а журналы транзакций архивируются значительно чаще — каждые 30-60 минут. Процесс восстановления в этом случае включает восстановление последней полной копии и последующее применение всех архивов журналов транзакций в хронологическом порядке. Это позволяет "накатить" на базу все подтверждённые транзакции практически до момента сбоя.

Что касается мгновенного автоматического переключения при отказе, то такой кейс не только возможен, но и является краеугольным камнем отказоустойчивых систем. Реализуется это с помощью механизмов высокой доступности, таких как синхронная репликация на горячую standby-базу (например, через технологии вроде Always On Availability Groups или аналогичные в других СУБД). В этой схеме все изменения на основной базе одновременно применяются на резервной реплике, обеспечивая её постоянную актуальность. В случае падения основной базы специализированное ПО кластеризации автоматически производит failover на standby-реплику за секунды, минимизируя простой и, в синхронном режиме, предотвращая потерю данных. Таким образом, для комплексной защиты нужна именно комбинация: классические бэкапы для долгосрочного хранения и восстановления после критических сбоев, и репликация для обеспечения бесперебойной работы и мгновенного переключения при аппаратных или программных отказах.


---

### Задание 2


Для резервного копирования и восстановления в PostgreSQL стандартными утилитами являются pg_dump и pg_restore. Пример команды резервирования, который создаёт архивный файл формата custom, подходящий для последующего гибкого восстановления, выглядит так: pg_dump -U username -F c -f /backups/mydb_backup.dump mydb. Здесь -U задаёт пользователя, -F c указывает на custom-формат, а -f определяет файл для вывода.

Для восстановления из полученного файла используется pg_restore. Команда может быть, например, такой: pg_restore -U username -d newdb -v /backups/mydb_backup.dump. Ключ -d указывает базу, в которую происходит восстановление (она должна быть создана заранее), а -v включает подробный вывод. Важно отметить, что pg_restore обладает гибкостью: позволяет восстанавливать отдельные таблицы, данные без схемы или наоборот, что особенно полезно после команды pg_dump -F c.

Что касается автоматизации, то этот процесс абсолютно поддаётся автоматизации. Наиболее простой и распространённый способ — создание cron-задания, которое будет выполнять pg_dump по расписанию, например, каждую ночь. Базовый пример строки в crontab мог бы выглядеть как 0 2 * * * pg_dump -U username -F c -f /backups/mydb_$(date +\%Y\%m\%d).dump mydb, что будет создавать резервную копию ежедневно в 2:00, добавляя дату к имени файла. Для более продвинутой автоматизации, включающей ротацию резервных копий, проверку их целостности и отправку уведомлений, обычно пишут скрипты-обёртки на Bash или Python, которые затем и запускаются из cron. Также существуют специализированные системы вроде Barman (Backup and Recovery Manager), которые предоставляют готовый инструментарий для полного управления жизненным циклом резервных копий PostgreSQL, включая инкременментальное бэкапирование и управление точками восстановления.





---

### Задание 3

Что касается инкрементного резервного копирования в MySQL, то стоит сразу отметить, что штатная утилита mysqldump эту задачу в чистом виде не решает. Она предназначена в первую очередь для полных или частичных дампов. Для настоящего инкрементного бэкапа, который сохраняет только изменения с момента последней операции, требуется работа с бинарными логами (binary logs). Бинарные логи — это, по сути, журнал всех операций изменения данных (INSERT, UPDATE, DELETE), которые происходят на сервере. Процесс выглядит так: сначала делаем полный бэкап с помощью mysqldump, например, mysqldump -u root -p --single-transaction --flush-logs --master-data=2 db_name > full_backup.sql. Ключевой момент здесь — опция --flush-logs, которая закрывает текущий бинарный лог и начинает новый. После этого мы можем периодически сохранять содержимое этих закрытых бинарных логов. Восстановление будет происходить в два этапа: разворачивание полного дампа и последующее применение бинарных логов начиная с позиции, которая была актуальна на момент создания полного бэкапа, с помощью утилиты mysqlbinlog.

Ответ на вопрос о реплике заключается в её основном предназначении — распределении нагрузки и повышении отказоустойчивости. Преимущество реплики перед обычным бэкапом проявляется в нескольких ключевых сценариях. Самый главный — это минимальное время простоя (RTO) при сбое на основном сервере. В случае падения мастера вы можете практически мгновенно перенаправить трафик на реплику, которая уже является работающей копией базы данных, в то время как восстановление из бэкапа требует времени на разворачивание дампа, что может занять часы на больших объёмах данных. Кроме того, реплика идеально подходит для создания консистентных бэкапов без остановки основного сервера: вы можете остановить репликацию на реплике, сделать с неё стабильный полный дамп, не нагружая мастер, и затем возобновить репликацию. Это же позволяет использовать реплику для выполнения различных аналитических запросов, которые не должны мешать основной рабочей нагрузке. Таким образом, репликация решает задачи высокой доступности и оперативного переключения, в то время как традиционное резервное копирование — это страховка на случай более серьёзных катастроф, когда нужно восстановить данные на определённый момент времени в прошлом.



![Скрин 1](screenshots/hw8-03s1.png)
![Скрин 2](screenshots/hw8-03s2.png)
